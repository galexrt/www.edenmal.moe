<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ceph on Edenmal</title><link>https://edenmal.moe/tags/Ceph/</link><description>Recent content in Ceph on Edenmal</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© This page/post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License, please give source if you wish to quote or reproduce.</copyright><lastBuildDate>Fri, 31 Jan 2020 19:06:12 +0100</lastBuildDate><atom:link href="https://edenmal.moe/tags/Ceph/index.xml" rel="self" type="application/rss+xml"/><item><title>FOSDEM'20 Brussels</title><link>https://edenmal.moe/post/2020/FOSDEM20/</link><pubDate>Fri, 31 Jan 2020 19:06:12 +0100</pubDate><guid>https://edenmal.moe/post/2020/FOSDEM20/</guid><description>Checkout the original publication of this article on the The Cloud Report site, where it was posted originally, here: The Cloud Report - FOSDEM’2020 Brussels.
Thanks to The Cloud Report for allowing me to write and publish the post on their blog!
I&amp;rsquo;m sitting in the ICE train back home from FOSDEM'2020 Brussels, and I’ve got only one thing to say: &amp;ldquo;What a wonderful weekend!&amp;rdquo;
FOSDEM, a weekend in Brussles, Belgium, where great minds in the form of developers, administrators and engineers meet and connect.</description></item><item><title>Rook: New Winds in the v1.1 release</title><link>https://edenmal.moe/post/2020/Rook-New-Winds-in-the-v1-1-release/</link><pubDate>Mon, 06 Jan 2020 15:20:10 +0100</pubDate><guid>https://edenmal.moe/post/2020/Rook-New-Winds-in-the-v1-1-release/</guid><description>This is a cross post of an older post from The Cloud Report, be sure to checkout the The Cloud Report website.
Thanks to them for allowing me to write and publish the post on their blog!
Preface Rook is a storage orchestrator for Kubernetes using the operator pattern. That means that Rook can run, e.g., Ceph, EdgeFS, Yugabyte and other persistence providers in a Kubernetes cluster. This allows applications to create, e.</description></item><item><title>FOSDEM'19 Brussels</title><link>https://edenmal.moe/post/2019/FOSDEM19-Brussels/</link><pubDate>Sat, 23 Feb 2019 17:50:09 +0100</pubDate><guid>https://edenmal.moe/post/2019/FOSDEM19-Brussels/</guid><description>FOSDEM was from Saturday, 02.02. to Sunday, 03.02.2019 in Brussels, Belgium.
Saturday FOSDEM&amp;#39;19 Brussels - Snow on Saturday FOSDEM&amp;#39;19 Brussels - ULB FOSDEM middle &amp;#39;street&amp;#39; with food trucks FOSDEM&amp;#39;19 Brussels - Booth area FOSDEM&amp;#39;19 Brussels - Gluster, Ceph and Rook booth FOSDEM&amp;#39;19 Brussels - openSUSE Original &amp;#39;Tumbleweed&amp;#39; Beer Extra The Belgian know how to make freaking awesome waffles! LOOK AT THOSE WAFFLES!!!
FOSDEM&amp;#39;19 Brussels - Le Funambule Waffle Selection If you are in Brussels, go to Le Funambule in the inner city of Brussels:</description></item><item><title>Rook more than Ceph</title><link>https://edenmal.moe/post/2019/Rook-more-than-Ceph/</link><pubDate>Mon, 07 Jan 2019 08:13:53 +0100</pubDate><guid>https://edenmal.moe/post/2019/Rook-more-than-Ceph/</guid><description>Checkout the orignal publication of this article on the The Cloud Report site here: The Cloud Report - Rook more than Ceph.
Preface Rook allows you to run Ceph and other storage backends in Kubernetes with ease. Consumption of storage, especially block and filesystem storage, can be consumed through Kubernetes native ways. this allows users of a Kubernetes cluster to consume storage easily as in &amp;ldquo;any&amp;rdquo; other standard Kubernetes cluster out there.</description></item><item><title>Ceph Day Berlin 2018</title><link>https://edenmal.moe/post/2018/Ceph-Day-Berlin-2018/</link><pubDate>Mon, 12 Nov 2018 08:00:53 +0100</pubDate><guid>https://edenmal.moe/post/2018/Ceph-Day-Berlin-2018/</guid><description>NOTE
All credit for the slides in the pictures goes to their creators!
NOTE
If you are in one of these pictures and want it removed, please contact me by email (see about/imprint page).
Slides The slides of the talks can be found here: Ceph Community presentations channel - SlideShare.
Welcome &amp;amp; Kickoff Ceph Day Berlin 2018 - Cloudical team arrived at the conference center I arrived with my colleagues from Cloudical at the Ceph Day Berlin location, which at the same time was the location for OpenStack Summit.</description></item><item><title>Ceph Day Darmstadt 2018</title><link>https://edenmal.moe/post/2018/Ceph-Day-Germany-2018/</link><pubDate>Wed, 07 Feb 2018 06:20:53 +0200</pubDate><guid>https://edenmal.moe/post/2018/Ceph-Day-Germany-2018/</guid><description>NOTE
All credit for the slides in the pictures goes to their creators!
NOTE
If you are in one of these pictures and want it removed, please contact me by email (see about/imprint page).
Welcome &amp;amp; Kickoff On my way to Ceph Day Darmstadt 2018 We got some small sweet breakfast snacks and coffee to start the day off!
Ceph Day Darmstadt 2018 Kickoff Talks Ceph Luminous is out what&amp;rsquo;s in it for you?</description></item><item><title>Ceph: rbd bench Commands</title><link>https://edenmal.moe/post/2017/Ceph-rbd-bench-Commands/</link><pubDate>Sat, 05 Aug 2017 23:53:35 +0200</pubDate><guid>https://edenmal.moe/post/2017/Ceph-rbd-bench-Commands/</guid><description>Intro The reference to these commands is from Sébastien Han Blog Post &amp;ldquo;Ceph: validate that the RBD cache is active&amp;rdquo; and the rbd man Page. For more posts about Ceph, take a look at Sébastien Han Blog.
Requisite - RBD image for running the Benchmarks To be able to run a rbd benchmark, you need to create an image. The command to create an image for this would be:
$ RBD_IMAGE_NAME=&amp;#34;bench1&amp;#34; $ rbd create --size=10G $RBD_IMAGE_NAME rbd bench Flags Takes normal rbd command flags like:</description></item><item><title>Ceph: Build your own cluster on CentOS</title><link>https://edenmal.moe/post/2016/Ceph-Build-your-own-cluster-on-CentOS/</link><pubDate>Fri, 29 Jul 2016 09:29:00 +0200</pubDate><guid>https://edenmal.moe/post/2016/Ceph-Build-your-own-cluster-on-CentOS/</guid><description>Ceph is an object, a block and filesystem storage system.
As you can see from the Ceph.com visitors map here, people all around the world search for it. You can also see some metrics about the Ceph project at their metrics site here.
I&amp;rsquo;m going to go over the installation of a two node Ceph storage cluster. You can then build on those storage nodes and choose multiple storage types you want to use.</description></item><item><title>SteamCMD: Not working on CephFS</title><link>https://edenmal.moe/post/2016/SteamCMD-Not-working-on-CephFS/</link><pubDate>Tue, 26 Jul 2016 18:30:53 +0200</pubDate><guid>https://edenmal.moe/post/2016/SteamCMD-Not-working-on-CephFS/</guid><description>See title.
Yes, you read right. SteamCMD is not working on CephFS (and maybe GlusterFS too, I can&amp;rsquo;t test it on GlusterFS ). The reason for that is a &amp;ldquo;failing&amp;rdquo; getdents when on the CephFS. A colleague told me that error may be related to the st_size and the rbytes of CephFS.
strace on xfs filesystem:
[...] [pid 123] stat64(&amp;#34;./zip0.zip&amp;#34;, 0xf71c9c40) = -1 ENOENT (No such file or directory) [pid 123] open(&amp;#34;.</description></item></channel></rss>